# AutoGraph - Automated Knowledge Graph Generation

AutoGraph ist ein modulares Framework zur automatisierten Erstellung von Knowledge Graphs aus verschiedenen Datenquellen mit LLM-unterstÃ¼tzter Pipeline-Optimierung.

## Features

ðŸš€ **Modulare Pipeline-Architektur**
- Austauschbare Extraktoren fÃ¼r verschiedene Datenquellen
- Konfigurierbare Verarbeitungsmodule (NER, Relation Extraction, Entity Linking)
- Flexible Storage-Backends (Neo4j)

ðŸ¤– **LLM-unterstÃ¼tzte Optimierung**
- Automatische Pipeline-Konfiguration basierend auf DatendomÃ¤ne
- QualitÃ¤tsbewertung durch Large Language Models
- Iterative Verbesserung der ExtraktionsqualitÃ¤t

ðŸ”— **Knowledge Graph Integration**
- Native Neo4j-UnterstÃ¼tzung
- Cypher-Abfragen fÃ¼r Graph-Exploration
- Strukturierte Datenextraktion und -speicherung

## Installation

```bash
# Repository klonen
git clone <repository-url>
cd AutoGraph

# Dependencies installieren mit uv
uv sync

# Optional: Entwicklungstools installieren
uv sync --group dev
```

## Schnellstart

### 1. Konfiguration erstellen

```bash
# Interaktive Konfiguration
uv run autograph init

# Oder manuell eine autograph-config.yaml erstellen
```

### 2. Pipeline ausfÃ¼hren

```bash
# Text-Dateien verarbeiten
uv run autograph run ./data/documents/ --domain medizin

# Einzelne Datei verarbeiten
uv run autograph run ./data/sample.txt
```

### 3. Programmatische Nutzung

```python
from autograph import AutoGraphPipeline
from autograph.config import AutoGraphConfig
from autograph.extractors import TextExtractor
from autograph.processors import NERProcessor
from autograph.storage import Neo4jStorage

# Konfiguration laden
config = AutoGraphConfig.from_file("autograph-config.yaml")

# Pipeline-Komponenten
extractor = TextExtractor(config.extractor.model_dump())
processors = [NERProcessor(config.processor.model_dump())]
storage = Neo4jStorage(config.neo4j.model_dump())

# Pipeline erstellen und ausfÃ¼hren
pipeline = AutoGraphPipeline(
    config=config,
    extractor=extractor,
    processors=processors,
    storage=storage
)

result = pipeline.run("./data/sample.txt")
print(f"Extrahiert: {len(result.entities)} EntitÃ¤ten")
```

### 4. Interaktives MenÃ¼

```bash
# Starte das interaktive MenÃ¼
uv run autograph menu
```

Das MenÃ¼ bietet:
- ðŸ“„ Text verarbeiten (NER + Beziehungen)
- ðŸ§  Nur NER (Named Entity Recognition)
- ðŸ”— Nur Beziehungsextraktion
- ðŸ—‚ï¸ Datenbank anzeigen/verwalten
- ðŸ“Š Detaillierte Statistiken

## ðŸŽ¯ DomÃ¤nen-System

AutoGraph unterstÃ¼tzt **domÃ¤nen-spezifische Beziehungsextraktion** fÃ¼r verschiedene Fachbereiche:

### ðŸ“‹ VerfÃ¼gbare DomÃ¤nen

#### ðŸ’¼ **Wirtschaft** (`wirtschaft`)
Spezialisiert auf Unternehmensbeziehungen:
- **Ãœbernahmen**: "Microsoft Ã¼bernimmt LinkedIn" â†’ `Ã¼bernimmt`
- **Investitionen**: "Google investiert in KI" â†’ `investiert_in`  
- **Marktdominanz**: "Amazon dominiert Cloud-Markt" â†’ `dominiert_Markt`

#### ðŸ¥ **Medizin** (`medizin`)
Fokus auf medizinische Beziehungen:
- **Diagnosen**: "Patient hat Diabetes" â†’ `hat_Diagnose`
- **Behandlungen**: "Arzt behandelt mit Medikament" â†’ `behandelt_mit`
- **Symptome**: "Patient zeigt Symptome" â†’ `zeigt_Symptom`

#### ðŸ’» **Technologie** (`technologie`)
Tech-spezifische Beziehungen:
- **Entwicklung**: "Apple entwickelt iOS" â†’ `entwickelt`
- **Technologie-Nutzung**: "App nutzt KI" â†’ `nutzt_Technologie`
- **KompatibilitÃ¤t**: "System ist kompatibel mit..." â†’ `ist_kompatibel_mit`

### ðŸš€ DomÃ¤nen-Verwendung

```bash
# CLI mit DomÃ¤ne
uv run autograph run firma.txt --domain wirtschaft
uv run autograph run patient.txt --domain medizin

# Processor-Auswahl
uv run autograph run text.txt --processor both    # NER + Beziehungen (Standard)
uv run autograph run text.txt --processor ner     # Nur NER
uv run autograph run text.txt --processor relation # Nur Beziehungen
```

### ðŸ“Š DomÃ¤nen-Vorteile

**Ohne DomÃ¤ne:**
```
"Microsoft Ã¼bernimmt LinkedIn" â†’ arbeitet_mit (0.5 Konfidenz)
```

**Mit DomÃ¤ne "wirtschaft":**
```
"Microsoft Ã¼bernimmt LinkedIn" â†’ Ã¼bernimmt (0.9 Konfidenz)
```

**Vorteile:**
- âœ… **HÃ¶here Genauigkeit** fÃ¼r Fachbegriffe
- âœ… **Spezifischere Beziehungstypen** 
- âœ… **Bessere Konfidenzwerte**
- âœ… **Kontextuelle Relevanz**

## Projektstruktur

```
AutoGraph/
â”œâ”€â”€ src/autograph/
â”‚   â”œâ”€â”€ core/              # Kern-Pipeline-Logik
â”‚   â”œâ”€â”€ extractors/        # Datenextraktoren
â”‚   â”œâ”€â”€ processors/        # Verarbeitungsmodule
â”‚   â”œâ”€â”€ storage/           # Storage-Backends
â”‚   â”œâ”€â”€ evaluation/        # LLM-Bewertung
â”‚   â”œâ”€â”€ config.py          # Konfiguration
â”‚   â””â”€â”€ cli.py            # Command-Line Interface
â”œâ”€â”€ tests/                 # Tests
â”œâ”€â”€ docs/                  # Dokumentation
â””â”€â”€ examples/             # Beispiele
```

## Konfiguration

AutoGraph nutzt YAML-Konfigurationsdateien:

```yaml
project_name: "mein-knowledge-graph"

neo4j:
  uri: "bolt://localhost:7687"
  username: "neo4j"
  password: "your-password"

llm:
  base_url: "http://localhost:11434/v1"  # Ollama
  api_key: "not-needed"                  # FÃ¼r lokale APIs oft nicht nÃ¶tig
  model: "qwen2.5:latest"                # Ihr bevorzugtes Modell

extractor:
  text_chunking: true
  chunk_size: 1000

processor:
  ner_model: "de_core_news_lg"
  ner_confidence_threshold: 0.8
  relation_confidence_threshold: 0.6
```

### LLM-Provider Konfiguration

AutoGraph unterstÃ¼tzt jeden OpenAI-kompatiblen Endpunkt. Hier sind Beispiele fÃ¼r verschiedene Provider:

**Ollama (lokal):**
```yaml
llm:
  base_url: "http://localhost:11434/v1"
  api_key: "not-needed"
  model: "qwen2.5:latest"
```

**OpenAI:**
```yaml
llm:
  base_url: "https://api.openai.com/v1"
  api_key: "your-openai-api-key"
  model: "gpt-3.5-turbo"
```

**LocalAI:**
```yaml
llm:
  base_url: "http://localhost:8080/v1"
  api_key: "not-needed"
  model: "your-local-model"
```

**LM Studio:**
```yaml
llm:
  base_url: "http://localhost:1234/v1"
  api_key: "not-needed"
  model: "your-model"
```

## Komponenten

### Extraktoren
- **TextExtractor**: Verarbeitet TXT, MD, RST Dateien
- **TableExtractor**: (geplant) CSV, Excel Dateien
- **WebExtractor**: (geplant) Web Scraping

### ðŸ¤– Prozessoren - ML-Enhanced!

#### 1. **Rule-Based RelationExtractor** (Basis)
- **NERProcessor**: Named Entity Recognition mit SpaCy
- **RelationExtractor**: Erweiterte Beziehungsextraktion mit syntaktischen Mustern
- **EntityLinker**: (geplant) Entity Linking

#### 2. **ðŸ¤– ML RelationExtractor** âœ… **NEU IMPLEMENTIERT!**
- **BERT-basiert**: deepset/gbert-base fÃ¼r deutsche Texte
- **T-Systems RoBERTa**: Speziell optimiert fÃ¼r deutschsprachige Relation Extraction
- **Automatische EntitÃ¤ten**: Keine manuellen Entity-Listen erforderlich
- **Domain-Templates**: Wirtschaft, Medizin, Wissenschaft
- **Performance**: 6 Relationen in 5.93s mit 0.595-0.707 Konfidenz

#### 3. **ðŸ”„ Hybrid RelationExtractor** âœ… **ENSEMBLE-SYSTEM!**
- **Best of Both**: Kombiniert Rule-based + ML AnsÃ¤tze
- **Weighted Union**: Konfigurierbare ML/Rule-Gewichtung
- **Performance-Monitoring**: Automatische Delta-Erkennung
- **Fallback-System**: Rules bei ML-Unsicherheit

### ðŸŽ¯ ML-Konfiguration
```python
# ML-Extractor
ml_config = {
    'sentence_model_name': 'T-Systems-onsite/german-roberta-sentence-transformer-v2',
    'ml_confidence_threshold': 0.5,
    'automatic_entity_detection': True,
    'gpu_enabled': True
}

# Hybrid-System  
hybrid_config = {
    "ensemble_method": "weighted_union",
    "ml_weight": 0.7,     # ML-PrÃ¤ferenz
    "rule_weight": 0.3    # Rule-Fallback
}
```

## Erweiterte Beziehungsextraktion

AutoGraph nutzt einen **mehrstufigen Ansatz** fÃ¼r automatisierte Beziehungserkennung:

### ðŸ” **Erkennungsmethoden**

1. **Dependency-basierte Extraktion**
   - Nutzt syntaktische AbhÃ¤ngigkeiten von SpaCy
   - Erkennt Subjekt-Verb-Objekt Strukturen automatisch

2. **Pattern-basierte Extraktion**  
   - 8+ vordefinierte Beziehungsmuster
   - DomÃ¤nen-spezifische Erweiterungen
   - Keyword-basierte Triggererkennung

3. **Satzstruktur-basierte Extraktion**
   - Ko-Referenz durch EntitÃ¤tennÃ¤he
   - Kontextuelle Verbindungen

### ðŸ“Š **Erkennungsleistung**

**Beispiel-Ergebnis** (Apple/Microsoft Text):
- **59 EntitÃ¤ten** (Personen, Organisationen, Orte)
- **43 Beziehungen** automatisch erkannt
- **Verschiedene Konfidenzlevel** (0.3-0.9)

**Erkannte Beziehungstypen:**
- `ist_CEO_von`, `grÃ¼ndete`, `befindet_sich_in`
- `konkurriert_mit`, `Ã¼bernimmt`, `investiert_in`
- `entwickelt`, `nutzt_Technologie`, `ist_kompatibel_mit`

### Storage
- **Neo4jStorage**: Neo4j Graph Database
- Weitere Backends geplant (ArangoDB, RDF Stores)

## LLM-Integration

AutoGraph nutzt LLMs fÃ¼r:
- **Pipeline-Optimierung**: Automatische Konfiguration basierend auf DatendomÃ¤ne
- **QualitÃ¤tsbewertung**: Bewertung der ExtraktionsqualitÃ¤t
- **Iterative Verbesserung**: VorschlÃ¤ge zur Pipeline-Optimierung

## Entwicklung

```bash
# Tests ausfÃ¼hren
uv run pytest

# Code-QualitÃ¤t prÃ¼fen
uv run black src/
uv run isort src/
uv run flake8 src/
uv run mypy src/
```

## Roadmap

**âœ… Implementiert:**
- [x] Modulare Pipeline-Architektur
- [x] TextExtractor fÃ¼r verschiedene Dateiformate
- [x] NER mit SpaCy (de_core_news_lg)
- [x] Erweiterte Beziehungsextraktion mit syntaktischen Mustern
- [x] DomÃ¤nen-spezifische Beziehungserkennung
- [x] Neo4j Graph Database Integration
- [x] OpenAI-kompatible LLM Integration (Ollama, OpenAI, LocalAI)
- [x] CLI mit interaktivem MenÃ¼
- [x] Datenbankmanagement (Anzeigen, LÃ¶schen, Schema-Erstellung)

**ðŸ”„ In Entwicklung/Geplant:**
- [ ] Web Scraping Extraktor
- [x] **Advanced Relation Extraction mit ML-Modellen** âœ… **IMPLEMENTIERT!**
- [ ] Ontologie-Integration
- [ ] Multi-Language Support
- [ ] REST API Interface
- [ ] Graph Visualisierung (Neo4j Browser, Gephi Export)
- [ ] Performance Optimierung
- [ ] TableExtractor fÃ¼r CSV/Excel
- [ ] Entity Linking

---

## ðŸ¤– Advanced Relation Extraction mit ML-Modellen - âœ… IMPLEMENTIERT

Das **ML-basierte Relation Extraction System** ist vollstÃ¤ndig implementiert und produktionsbereit!

### ðŸŽ¯ ML-Features

**Kernkomponenten:**
- **ML RelationExtractor**: BERT-basierte Relation Classification
- **T-Systems deutsches RoBERTa**: Speziell optimiert fÃ¼r deutsche Texte
- **Hybrid Ensemble-System**: Kombiniert Rule-based + ML AnsÃ¤tze
- **Automatische Entity-Erkennung**: Keine manuellen EntitÃ¤ten nÃ¶tig
- **Domain-spezifische Templates**: Medizin, Wirtschaft, Wissenschaft

### ðŸš€ Performance & Ergebnisse

**Live-Test Ergebnis:**
```
Text: "BMW kooperiert mit der UniversitÃ¤t MÃ¼nchen. Siemens investiert in Forschung."

ðŸ¤– ML-Relationen: 6 gefunden (in 5.93s)
  1. UniversitÃ¤t MÃ¼nchen --[kooperiert_mit]--> Forschung (Conf: 0.707)
  2. UniversitÃ¤t MÃ¼nchen --[kooperiert_mit]--> Siemens (Conf: 0.685)
  3. Siemens --[kooperiert_mit]--> Forschung (Conf: 0.664)
  4. UniversitÃ¤t MÃ¼nchen --[kooperiert_mit]--> BMW (Conf: 0.633)
  5. Forschung --[investiert_in]--> BMW (Conf: 0.608)
  6. Siemens --[investiert_in]--> BMW (Conf: 0.595)
```

### ðŸ”§ Technische Details

**Modelle:**
- **Primary BERT**: deepset/gbert-base (Deutsch-optimiert, 442MB)
- **T-Systems RoBERTa**: T-Systems-onsite/german-roberta-sentence-transformer-v2
- **Fallback**: Multilinguale Sentence Transformers

**Dependencies:**
- `transformers`: BERT-Modelle  
- `torch`: Deep Learning Backend
- `sentence-transformers`: Semantische Embeddings
- `sentencepiece`: Tokenizer Support
- `tiktoken`: Tokenizer Konvertierung

### ðŸ’» ML-Verwendung

**Einfache ML-Extraction:**
```python
from autograph.processors.ml_relation_extractor import MLRelationExtractor

config = {
    'sentence_model_name': 'T-Systems-onsite/german-roberta-sentence-transformer-v2',
    'ml_confidence_threshold': 0.5  # Optimaler Threshold
}

extractor = MLRelationExtractor(config)

# Automatische Entity-Erkennung + ML-Relationen
result = await extractor.process_async(
    "BMW kooperiert mit der UniversitÃ¤t MÃ¼nchen.", 
    domain='wirtschaft'
)

relations = result['relationships']  # 6 Relationen in 5.93s
```

**Hybrid-System (Rules + ML):**
```python
from autograph.processors.hybrid_relation_extractor import HybridRelationExtractor

config = {
    "ensemble_method": "weighted_union",
    "ml_weight": 0.7,     # ML-PrÃ¤ferenz
    "rule_weight": 0.3    # Rule-Fallback
}

hybrid = HybridRelationExtractor(config)
result = await hybrid.process_async(data, domain='wirtschaft')
```

### ðŸ“Š Domain-Templates

**Wirtschaft:**
- kooperiert_mit, investiert_in, Ã¼bernimmt, konkurriert_mit

**Medizin:**  
- behandelt, verursacht, wirkt_gegen, interagiert_mit

**Wissenschaft:**
- erforscht, entwickelt, publiziert_Ã¼ber, experimentiert_mit

**Allgemein:**
- gehÃ¶rt_zu, befindet_sich_in, arbeitet_fÃ¼r, verwendet

### ðŸŽ® ML-CLI-Integration

```bash
# ML-Relationen direkt per CLI
uv run autograph run text.txt --processor ml --domain wirtschaft

# Hybrid-Modus (Rules + ML)
uv run autograph run text.txt --processor hybrid --domain medizin
```

### âš¡ Performance-Optimierungen  

**Implementierte Verbesserungen:**
- âœ… Confidence-Threshold auf 0.5 (optimal fÃ¼r Produktion)
- âœ… Automatische Entity-Erkennung (keine manuellen EntitÃ¤ten nÃ¶tig)
- âœ… Performance-Monitoring (zeigt Entity-Pairs und Relationen)
- âœ… GPU/CPU Auto-Detection
- âœ… Lazy Model Loading (3-4s ersten Load)
- âœ… Batch-Processing fÃ¼r bessere Performance

**Technische Metriken:**
- **Model Loading**: 3-4s (T-Systems deutsch, einmalig)
- **Relation Extraction**: 5.93s fÃ¼r komplexe Texte
- **Confidence Range**: 0.595-0.707 (realistisch hoch)
- **Entity Detection**: Automatisch ohne Eingabe
- **Memory**: GPU/CPU optimiert

---

## Lizenz

AGPL v3 - Siehe LICENSE.md

