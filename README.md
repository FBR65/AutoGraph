# AutoGraph - Automated Knowledge Graph Generation

AutoGraph ist ein modulares Framework zur automatisierten Erstellung von Knowledge Graphs aus verschiedenen Datenquellen mit LLM-unterstÃ¼tzter Pipeline-Optimierung.

## Features

ğŸš€ **Modulare Pipeline-Architektur**
- Austauschbare Extraktoren fÃ¼r verschiedene Datenquellen
- Konfigurierbare Verarbeitungsmodule (NER, Relation Extraction, Entity Linking)
- Flexible Storage-Backends (Neo4j)

ğŸ¤– **LLM-unterstÃ¼tzte Optimierung**
- Automatische Pipeline-Konfiguration basierend auf DatendomÃ¤ne
- QualitÃ¤tsbewertung durch Large Language Models
- Iterative Verbesserung der ExtraktionsqualitÃ¤t

ğŸ”— **Knowledge Graph Integration**
- Native Neo4j-UnterstÃ¼tzung
- Cypher-Abfragen fÃ¼r Graph-Exploration
- Strukturierte Datenextraktion und -speicherung

## Installation

```bash
# Repository klonen
git clone <repository-url>
cd AutoGraph

# Dependencies installieren mit uv
uv sync

# Optional: Entwicklungstools installieren
uv sync --group dev
```

## Schnellstart

### 1. Konfiguration erstellen

```bash
# Interaktive Konfiguration
uv run autograph init

# Oder manuell eine autograph-config.yaml erstellen
```

### 2. Pipeline ausfÃ¼hren

```bash
# Text-Dateien verarbeiten
uv run autograph run ./data/documents/ --domain medizin

# Einzelne Datei verarbeiten
uv run autograph run ./data/sample.txt
```

### 3. Programmatische Nutzung

```python
from autograph import AutoGraphPipeline
from autograph.config import AutoGraphConfig
from autograph.extractors import TextExtractor
from autograph.processors import NERProcessor
from autograph.storage import Neo4jStorage

# Konfiguration laden
config = AutoGraphConfig.from_file("autograph-config.yaml")

# Pipeline-Komponenten
extractor = TextExtractor(config.extractor.model_dump())
processors = [NERProcessor(config.processor.model_dump())]
storage = Neo4jStorage(config.neo4j.model_dump())

# Pipeline erstellen und ausfÃ¼hren
pipeline = AutoGraphPipeline(
    config=config,
    extractor=extractor,
    processors=processors,
    storage=storage
)

result = pipeline.run("./data/sample.txt")
print(f"Extrahiert: {len(result.entities)} EntitÃ¤ten")
```

### 4. Interaktives MenÃ¼

```bash
# Starte das interaktive MenÃ¼
uv run autograph menu
```

Das MenÃ¼ bietet:
- ğŸ“„ Text verarbeiten (NER + Beziehungen)
- ğŸ§  Nur NER (Named Entity Recognition)
- ğŸ”— Nur Beziehungsextraktion
- ğŸ—‚ï¸ Datenbank anzeigen/verwalten
- ğŸ“Š Detaillierte Statistiken

## ğŸ¯ DomÃ¤nen-System

AutoGraph unterstÃ¼tzt **domÃ¤nen-spezifische Beziehungsextraktion** fÃ¼r verschiedene Fachbereiche:

### ğŸ“‹ VerfÃ¼gbare DomÃ¤nen

#### ğŸ’¼ **Wirtschaft** (`wirtschaft`)
Spezialisiert auf Unternehmensbeziehungen:
- **Ãœbernahmen**: "Microsoft Ã¼bernimmt LinkedIn" â†’ `Ã¼bernimmt`
- **Investitionen**: "Google investiert in KI" â†’ `investiert_in`  
- **Marktdominanz**: "Amazon dominiert Cloud-Markt" â†’ `dominiert_Markt`

#### ğŸ¥ **Medizin** (`medizin`)
Fokus auf medizinische Beziehungen:
- **Diagnosen**: "Patient hat Diabetes" â†’ `hat_Diagnose`
- **Behandlungen**: "Arzt behandelt mit Medikament" â†’ `behandelt_mit`
- **Symptome**: "Patient zeigt Symptome" â†’ `zeigt_Symptom`

#### ğŸ’» **Technologie** (`technologie`)
Tech-spezifische Beziehungen:
- **Entwicklung**: "Apple entwickelt iOS" â†’ `entwickelt`
- **Technologie-Nutzung**: "App nutzt KI" â†’ `nutzt_Technologie`
- **KompatibilitÃ¤t**: "System ist kompatibel mit..." â†’ `ist_kompatibel_mit`

### ğŸš€ DomÃ¤nen-Verwendung

```bash
# CLI mit DomÃ¤ne
uv run autograph run firma.txt --domain wirtschaft
uv run autograph run patient.txt --domain medizin

# Processor-Auswahl
uv run autograph run text.txt --processor both    # NER + Beziehungen (Standard)
uv run autograph run text.txt --processor ner     # Nur NER
uv run autograph run text.txt --processor relation # Nur Beziehungen
```

### ğŸ“Š DomÃ¤nen-Vorteile

**Ohne DomÃ¤ne:**
```
"Microsoft Ã¼bernimmt LinkedIn" â†’ arbeitet_mit (0.5 Konfidenz)
```

**Mit DomÃ¤ne "wirtschaft":**
```
"Microsoft Ã¼bernimmt LinkedIn" â†’ Ã¼bernimmt (0.9 Konfidenz)
```

**Vorteile:**
- âœ… **HÃ¶here Genauigkeit** fÃ¼r Fachbegriffe
- âœ… **Spezifischere Beziehungstypen** 
- âœ… **Bessere Konfidenzwerte**
- âœ… **Kontextuelle Relevanz**

## Projektstruktur

```
AutoGraph/
â”œâ”€â”€ src/autograph/
â”‚   â”œâ”€â”€ core/              # Kern-Pipeline-Logik
â”‚   â”œâ”€â”€ extractors/        # Datenextraktoren
â”‚   â”œâ”€â”€ processors/        # Verarbeitungsmodule
â”‚   â”œâ”€â”€ storage/           # Storage-Backends
â”‚   â”œâ”€â”€ evaluation/        # LLM-Bewertung
â”‚   â”œâ”€â”€ config.py          # Konfiguration
â”‚   â””â”€â”€ cli.py            # Command-Line Interface
â”œâ”€â”€ tests/                 # Tests
â”œâ”€â”€ docs/                  # Dokumentation
â””â”€â”€ examples/             # Beispiele
```

## Konfiguration

AutoGraph nutzt YAML-Konfigurationsdateien:

```yaml
project_name: "mein-knowledge-graph"

neo4j:
  uri: "bolt://localhost:7687"
  username: "neo4j"
  password: "your-password"

llm:
  base_url: "http://localhost:11434/v1"  # Ollama
  api_key: "not-needed"                  # FÃ¼r lokale APIs oft nicht nÃ¶tig
  model: "qwen2.5:latest"                # Ihr bevorzugtes Modell

extractor:
  text_chunking: true
  chunk_size: 1000

processor:
  ner_model: "de_core_news_lg"
  ner_confidence_threshold: 0.8
  relation_confidence_threshold: 0.6
```

### LLM-Provider Konfiguration

AutoGraph unterstÃ¼tzt jeden OpenAI-kompatiblen Endpunkt. Hier sind Beispiele fÃ¼r verschiedene Provider:

**Ollama (lokal):**
```yaml
llm:
  base_url: "http://localhost:11434/v1"
  api_key: "not-needed"
  model: "qwen2.5:latest"
```

**OpenAI:**
```yaml
llm:
  base_url: "https://api.openai.com/v1"
  api_key: "your-openai-api-key"
  model: "gpt-3.5-turbo"
```

**LocalAI:**
```yaml
llm:
  base_url: "http://localhost:8080/v1"
  api_key: "not-needed"
  model: "your-local-model"
```

**LM Studio:**
```yaml
llm:
  base_url: "http://localhost:1234/v1"
  api_key: "not-needed"
  model: "your-model"
```

## Komponenten

### Extraktoren
- **TextExtractor**: Verarbeitet TXT, MD, RST Dateien
- **TableExtractor**: (geplant) CSV, Excel Dateien
- **WebExtractor**: (geplant) Web Scraping

### Prozessoren
- **NERProcessor**: Named Entity Recognition mit SpaCy
- **RelationExtractor**: âœ… **Erweiterte Beziehungsextraktion** mit syntaktischen Mustern
- **EntityLinker**: (geplant) Entity Linking

## Erweiterte Beziehungsextraktion

AutoGraph nutzt einen **mehrstufigen Ansatz** fÃ¼r automatisierte Beziehungserkennung:

### ğŸ” **Erkennungsmethoden**

1. **Dependency-basierte Extraktion**
   - Nutzt syntaktische AbhÃ¤ngigkeiten von SpaCy
   - Erkennt Subjekt-Verb-Objekt Strukturen automatisch

2. **Pattern-basierte Extraktion**  
   - 8+ vordefinierte Beziehungsmuster
   - DomÃ¤nen-spezifische Erweiterungen
   - Keyword-basierte Triggererkennung

3. **Satzstruktur-basierte Extraktion**
   - Ko-Referenz durch EntitÃ¤tennÃ¤he
   - Kontextuelle Verbindungen

### ğŸ“Š **Erkennungsleistung**

**Beispiel-Ergebnis** (Apple/Microsoft Text):
- **59 EntitÃ¤ten** (Personen, Organisationen, Orte)
- **43 Beziehungen** automatisch erkannt
- **Verschiedene Konfidenzlevel** (0.3-0.9)

**Erkannte Beziehungstypen:**
- `ist_CEO_von`, `grÃ¼ndete`, `befindet_sich_in`
- `konkurriert_mit`, `Ã¼bernimmt`, `investiert_in`
- `entwickelt`, `nutzt_Technologie`, `ist_kompatibel_mit`

### Storage
- **Neo4jStorage**: Neo4j Graph Database
- Weitere Backends geplant (ArangoDB, RDF Stores)

## LLM-Integration

AutoGraph nutzt LLMs fÃ¼r:
- **Pipeline-Optimierung**: Automatische Konfiguration basierend auf DatendomÃ¤ne
- **QualitÃ¤tsbewertung**: Bewertung der ExtraktionsqualitÃ¤t
- **Iterative Verbesserung**: VorschlÃ¤ge zur Pipeline-Optimierung

## Entwicklung

```bash
# Tests ausfÃ¼hren
uv run pytest

# Code-QualitÃ¤t prÃ¼fen
uv run black src/
uv run isort src/
uv run flake8 src/
uv run mypy src/
```

## Roadmap

**âœ… Implementiert:**
- [x] Modulare Pipeline-Architektur
- [x] TextExtractor fÃ¼r verschiedene Dateiformate
- [x] NER mit SpaCy (de_core_news_lg)
- [x] Erweiterte Beziehungsextraktion mit syntaktischen Mustern
- [x] DomÃ¤nen-spezifische Beziehungserkennung
- [x] Neo4j Graph Database Integration
- [x] OpenAI-kompatible LLM Integration (Ollama, OpenAI, LocalAI)
- [x] CLI mit interaktivem MenÃ¼
- [x] Datenbankmanagement (Anzeigen, LÃ¶schen, Schema-Erstellung)

**ğŸ”„ In Entwicklung/Geplant:**
- [ ] Web Scraping Extraktor
- [ ] Advanced Relation Extraction mit ML-Modellen
- [ ] Ontologie-Integration
- [ ] Multi-Language Support
- [ ] REST API Interface
- [ ] Graph Visualisierung (Neo4j Browser, Gephi Export)
- [ ] Performance Optimierung
- [ ] TableExtractor fÃ¼r CSV/Excel
- [ ] Entity Linking

## Lizenz

AGPL v3 - Siehe LICENSE.md

